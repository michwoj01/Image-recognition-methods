{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transforms.ToTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.mean(torch.tensor(trainset.data).float(), dim=(0, 1, 2)) / 255.0\n",
    "std = torch.std(torch.tensor(trainset.data).float(), dim=(0, 1, 2)) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(trainset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomResizedCrop(size=32, scale=(0.8, 1.0), ratio=(0.9, 1.1)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean, std)])\n",
    "\n",
    "trainset.transform = transform\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=16, shuffle=True, num_workers=2)\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 64, 3, 4, 4])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbAAAAGuCAYAAADxklPBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAi3ElEQVR4nO3df3xU9Z3v8XfiJDNIkgkRnZRCLLdSkCpUYoFI3VqIcl1todDWbrWl6n24SvDyw90qu1Wqa29Qu4K0IF514bbVxsVbVFiL5RE12BooBLiiItI2K1GYIG0zQyITCPneP2yzpHK+J5OZYfIlr+fjcR4PM5/zPeeTbyZ5e8L55uQYY4wAAHBMbrYbAACgNwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMC2W7gr3V2dmr//v0qLCxUTk5OttsBAJxCxhgdPnxYQ4YMUW6uzzWWyZAf/ehH5txzzzXBYNCMHz/ebNmypUfjmpqajCQ2NjY2tn68NTU1+eZFRn6F+NRTT2nBggVatGiRtm/frrFjx2rq1Kk6ePCg79jCwsJMtAQAcEiPsiDVK62TGT9+vKmqqur6+Pjx42bIkCGmurrad2wsFst68rOxsbGxZXeLxWK+eZH2K7CjR4+qoaFBlZWVXa/l5uaqsrJS9fX1H9m/vb1d8Xi82wYAgJ+0B9ihQ4d0/PhxRSKRbq9HIhFFo9GP7F9dXa1wONy1DRs2LN0tAQBOQ1m/jX7hwoWKxWJdW1NTU7ZbAgA4IO230Q8ePFhnnHGGmpubu73e3Nys0tLSj+wfDAYVDAbT3QYA4DSX9iuw/Px8lZeXq7a2tuu1zs5O1dbWqqKiIt2nAwD0UxlZyLxgwQLNmjVLF198scaPH6+lS5eqra1N119/fSZOBwDohzISYNdcc43ef/993XXXXYpGo/rMZz6jDRs2fOTGDgAAeivHGGOy3cSJ4vG4wuFwttsAAGRRLBZTUVGRdZ+s34UIAEBvEGAAACcRYAAAJxFgAAAn9bnngaUqm/ekpPr8smz17mrfUmq903fy+mPfEt+bvXEqnufIFRgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJgWw3kG45OTnZbqHXXO2dvk8t+j71XO3d1b57iiswAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAk06754EZY7J27lSfvZOt3l3tW0qtd/pOXn/sW+J7szdOxbPIuAIDADiJAAMAOIkAAwA4iQADADiJAAMAOIkAAwA46bS7jf6R39vrl/83e92nDADoI7gCAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOIkAAwA4Kel1YJs2bdIDDzyghoYGHThwQGvXrtX06dO76sYYLVq0SI8++qhaWlo0adIkPfzwwxoxYkQ6+/Z08ydH2ncoGG0tF02+0rP25RlX96alHnvVUrsko2cGAPckfQXW1tamsWPHavny5Set33///Vq2bJlWrlypLVu2aODAgZo6daoSiUTKzQIA8BdJX4FdeeWVuvLKk1+lGGO0dOlSffe739W0adMkST/+8Y8ViUT0zDPP6Otf/3pq3QIA8Gdp/TewxsZGRaNRVVZWdr0WDoc1YcIE1dfXn3RMe3u74vF4tw0AAD9pDbBoNCpJikQi3V6PRCJdtb9WXV2tcDjctQ0bNiydLQEATlNZvwtx4cKFisViXVtTU1O2WwIAOCCtAVZaWipJam5u7vZ6c3NzV+2vBYNBFRUVddsAAPCT1gAbPny4SktLVVtb2/VaPB7Xli1bVFFRkc5TAQD6uaTvQmxtbdVvf/vbro8bGxu1c+dOlZSUqKysTPPmzdO9996rESNGaPjw4brzzjs1ZMiQbmvFMuttazW/1V4f0djuWXv3uWbPWjrcdc0yz1pp8bnWsReN/4K1PupvM3dl+4GldmbGzgqgv0s6wLZt26YvfOG/flguWLBAkjRr1iytXr1a3/nOd9TW1qabbrpJLS0t+tznPqcNGzYoFAqlr2sAQL+XdIBddtllMsZ41nNycnTPPffonnvuSakxAABssn4XIgAAvUGAAQCcRIABAJxEgAEAnJRjbHdkZEE8Hlc4HM52GwCALIrFYr5/2IIrMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMC2W4AJxrtWflkwVnWkcVnh6z13Y0dnrUP9JK9LR/TvvZ/PGvDLqq0jh18/hBr/avT7Of+dE6OfQeLbD4KL4e+T6lU+pay17urfUup994TXIEBAJxEgAEAnESAAQCcRIABAJxEgAEAnESAAQCcxG30fcqbnpXftfoM9atnUOK52d7FjuusY3/yr29b6xu///HetNQj31/8f631f75jZsbOnVkH7eXDljlvsX89UvJatb0ebbbX//QH71pTBvuWpO8N9a4lLH1J6vxTwlo/dKg3DfXMC5d438peOP5S69hLlm5KdztpxxUYAMBJBBgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJOSabf2//JOLxuMLhcLbb6HPO9Kl/1qduWcWiJ5Ls5a8ttdT8+trhU/+JT32LT93mKp/6RZYn1DTZl/bopmJ7fVKLz8ktjM+xj6ZwbD/BFMa2+9R9plRFllqnz9gzfOp+3rPUBvuMTWUJ57k+Y/1ssNT+02fs9f/8KWs9/9491nqqj1OJxWIqKrJ91bkCAwA4igADADiJAAMAOIkAAwA4iQADADiJAAMAOIkAAwA4ieeBOWKQT/18n/o3LbVU14HdYql1+Iz93z71rUn2kowRPvVXLAuT6nzGHmpJspkkvOpz7Esyd+qU5KdYt8nm/4nn2xZZSioZ7VO3rDfUc0m3082wYu/ayy32sav+3f6Mtb+/N+l20o4rMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAk3geGACgz+F5YACA0xYBBgBwEgEGAHASAQYAcBIBBgBwEgEGAHASAQYAcBIBBgBwEgEGAHASAQYAcBIBBgBwEgEGAHASAQYAcBIBBgBwUiCZnaurq/Xzn/9cb731lgYMGKBLLrlE9913n0aOHNm1TyKR0G233aaamhq1t7dr6tSpWrFihSKRSNqbR8993FJ7L8Vjr7fUfuYz9okUz52KKT712lPSRfJKfOp7B/uMXxryLl5xqXVszjkbfc7uzSyx1zfNt9e3Wmq7fc79uE/dzwRL7avn28d+de511vrQoWM8a2dc/R37wX1cVepd+4+ofWyJTzr84Zj9SVw5OTn2A6RBUldgdXV1qqqq0ubNm7Vx40YdO3ZMV1xxhdra2rr2mT9/vtatW6c1a9aorq5O+/fv14wZM9LeOACgf0vqCmzDhg3dPl69erXOOeccNTQ06G/+5m8Ui8X0+OOP68knn9TkyZMlSatWrdL555+vzZs3a+LEienrHADQr6X0b2CxWEySVFLy4S81GhoadOzYMVVWVnbtM2rUKJWVlam+vv6kx2hvb1c8Hu+2AQDgp9cB1tnZqXnz5mnSpEm64IILJEnRaFT5+fkqLi7utm8kElE0evJfuFZXVyscDndtw4YN621LAIB+pNcBVlVVpddff101NTUpNbBw4ULFYrGurampKaXjAQD6h6T+Dewv5syZo/Xr12vTpk0aOnRo1+ulpaU6evSoWlpaul2FNTc3q7T05LfDBINBBYPB3rQBAOjHkroCM8Zozpw5Wrt2rV588UUNHz68W728vFx5eXmqrf2vG5D37Nmjffv2qaKiIj0dAwAgKccYY7+Z/wSzZ8/Wk08+qWeffbbb2q9wOKwBAwZIkm655RY9//zzWr16tYqKinTrrbdKkl599dUenSMejyscDifzOQA4wcxS+/8sPl1rWbk32r7KLJW1PYtn32+t37Hin3yO0NHrc2eWbZWlJH3Kp277vF5JspdTZ/0f7V+Pq/0WkvmIxWIqKiqy7pPUGR5++GFJ0mWXXdbt9VWrVunb3/62JGnJkiXKzc3VzJkzuy1kBgAgnZIKsJ5crIVCIS1fvlzLly/vdVMAAPjhbyECAJxEgAEAnESAAQCcRIABAJyU2n2OwGnM9n93nT5jJ/ncWv3rFB5iM+tvb7fWN79vv7357l++41n7zO5UH67j7Ycvvemzxzifuq23zPXtz+/2/pdOSRen2tVT7I+JORW4AgMAOIkAAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOCmpx6mcCjxOBaeDH/jU/yGFY79RbH9cyqrxl1jr75eWedZ+++PbrGN/ncIjTT49Yry1XlBxqbWe2PsHz9r/q1/dm5Z6LF8Rz9r/nPv31rHv+yy3/clvvD+vzvqH7I35utxSi/mM3eNT9xufmp48ToUrMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAk1gHBgDoc1gHBgA4bRFgAAAnEWAAACcRYAAAJxFgAAAnEWAAACcRYAAAJxFgAAAnEWAAACcRYAAAJxFgAAAnEWAAACcRYAAAJxFgAAAnBbLdAHA6WulTvzmFY//ap/4nnWutvyzvxxXV67WUzm1z4/DR1vpFD9xjP8ChDs/Sw/febx36xrvb7cf2cfPXqjxrd1ffbh1bcPZZ1vq2phbP2uc//XHrWD9zltR71l7Z9Tvr2KbGHdb6gEPvWOvv7XraWk8HrsAAAE4iwAAATiLAAABOIsAAAE4iwAAATiLAAABOIsAAAE5iHRiQAams8/Izw6c+Ufb1OTbeK61S19H4trX+7nPPWOutLd7ddRx6rzct9djeHd7rqR6+7z7r2IKA/cfsZ8df2queeuLuWRM9a693eNc+dK21WuozeuQ5OT57pI4rMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAk3KMMSbbTZwoHo8rHPZ+XhGA/infUjua4XPb/k8/5DPWb23dNy/6gmft8R0v+Yy2S+XH+wc+9TN96jk5qa0Di8ViKioqsu7DFRgAwEkEGADASQQYAMBJBBgAwEkEGADASQQYAMBJPE4F8PDpwDjP2hsd209hJ6eHmVd43y4uSa2NzdZ6wRHvG9KHjxttHfsDn0e1+FnwpemeNb8foq2JNmt91IUV3sUUb6P/4IB3LVFgH9vqc2yfp8ScElyBAQCcRIABAJxEgAEAnESAAQCcRIABAJxEgAEAnESAAQDcZJKwYsUKc+GFF5rCwkJTWFhoJk6caJ5//vmu+pEjR8zs2bNNSUmJGThwoJkxY4aJRqPJnMLEYjEjiY2NjY2tH2+xWMw3L5K6Ahs6dKgWL16shoYGbdu2TZMnT9a0adP0xhtvSJLmz5+vdevWac2aNaqrq9P+/fs1Y8aMZE4BAEDPJHV5dBKDBg0yjz32mGlpaTF5eXlmzZo1XbXdu3cbSaa+vr7Hx+MKjI2NjY0t7VdgJzp+/LhqamrU1tamiooKNTQ06NixY6qsrOzaZ9SoUSorK1N9fb3ncdrb2xWPx7ttAAD4STrAdu3apYKCAgWDQd18881au3atRo8erWg0qvz8fBUXF3fbPxKJKBqNeh6vurpa4XC4axs2bFjSnwQAoP9JOsBGjhypnTt3asuWLbrllls0a9Ysvfnmm71uYOHChYrFYl1bU1NTr48FAOg/kv57wvn5+TrvvPMkSeXl5dq6daseeughXXPNNTp69KhaWlq6XYU1NzertLTU83jBYFDBYDD5zgEA/VrK68A6OzvV3t6u8vJy5eXlqba2tqu2Z88e7du3TxUVlscFAADQC0ldgS1cuFBXXnmlysrKdPjwYT355JN6+eWX9cILLygcDuvGG2/UggULVFJSoqKiIt16662qqKjQxIkTM9U/AKCfSirADh48qG9961s6cOCAwuGwxowZoxdeeEGXX365JGnJkiXKzc3VzJkz1d7erqlTp2rFihUZaRwA0L/lGGNMtps4UTweVzgcznYbAIAsisViKioqsu7D30IEADiJAAMAOIkAAwA4iQADADgp6YXM6Ks+bq2WlF7kWftjdH26m0mba750u7X+1HP39frY/3DF/7LWdzW+7Vl7Ye/qXp83VVdVXGetd7Tax7+y6xXP2j997evWsd/9997P93tb7H+xpyNkH1/6Me/3eP7Z9n/sz8nJsR/ch/VeN5/b4D7w+Xp0JNo9a+FzfCbFxzu/826uo8M+tqPQXg/4tPbJktTmvCe4AgMAOIkAAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOIl1YKeN96zVP0bt9b7qqef+NWPHXvbLGmv9qF7L2LlT8R/1P/XZ4yxrNV/netYOBTL3cNm1z2+31s+78JPWeumI89PZTtp0+tQ7fH7KdoQyN+cB21ouv3VgPsfu0PFk20k7rsAAAE4iwAAATiLAAABOIsAAAE4iwAAATiLAAABOIsAAAE46DdeB+T0/J3FKukC6+K1G6b2+us4rdX+wVo9a5nTpkxvS3UyXux552lq/aMwYa33z3phn7YLzy3rVU09t2nTQs1ZQUGAdW1BwprVefHavWuoR2zO/Eke8n0Mm+X/nhQoyt36tp7gCAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOCnHGGOy3cSJ4vG4wuFwr8ffPPshaz2QZ185EApZbon1uQP/Bw/Nsu/g49oZ93vWnvj5Sp/Rv0/p3ABsbD+TRltHXvONr1jrf/eNKz1r06+2H9tP3a+9H6Pkd/u/QvaflQVn22+jH1mS2iqtWCymoqIi6z5cgQEAnESAAQCcRIABAJxEgAEAnESAAQCcRIABAJxEgAEAnHTarQMDALiPdWAAgNMWAQYAcBIBBgBwEgEGAHASAQYAcBIBBgBwEgEGAHASAQYAcBIBBgBwEgEGAHASAQYAcBIBBgBwEgEGAHASAQYAcBIBBgBwUiDbDaTbrBvut9YHhILW+uCzz/KslRYMto6d84//3Vr3s/KBjZ611tY269iOjo5en/eO73+l12MlaWW1d9/FgwqsY1uOJKz1nXvfs597xXXWus2UK+6x1t96823P2nvvbvc5+pu96Aj90YSKGz1rW+ofT+nY3/uXGs/a5Vd8wT44ZC8HQvb4mDDS+2dpunAFBgBwEgEGAHASAQYAcBIBBgBwEgEGAHASAQYAcNJpdxv9gNBAaz2QZ/+UAwHvekeH/ZbvVCU62j1rxcX2e1pDA+zLA0IFPvfEpqB0mPet8n5TVlxo/3pMHP1xa32l/fBW3/xShbUemHGpZ62jY5Z1bMsR76+lJM37x6utdZvvLfqptd7YuM9a/+3edzxruxvtyxb+GF1vrduN9qn/3qee2e+/bNm71/71SsXu3d5LQSZeMt46Nq/DJx4sP69OFa7AAABOIsAAAE4iwAAATiLAAABOIsAAAE4iwAAATiLAAABOSmkd2OLFi7Vw4ULNnTtXS5culSQlEgnddtttqqmpUXt7u6ZOnaoVK1YoEomko19/PmsXAnn29VCJVu9aa0Fm16G0dnifvNXSlyQFEvbPu+Bw5pb8RQ80e9b8HvIS8H0L9v4xMf7s61gCOu5dC5xhHTv0bPt6xFRMvHCktX75JeOs9VCB97q9RMI+35Om9H4d2IZn7OvXotE/WOvvNu73rDW+f8g69vF/u81a93PNjLs8ayHL2lFJOv+iMdb6BeO818ddPfVT9sZ8/N03vB+V5PcIpg6f90KGl8X2SK+vwLZu3apHHnlEY8Z0/+LMnz9f69at05o1a1RXV6f9+/drxowZKTcKAMCJehVgra2tuvbaa/Xoo49q0KBBXa/HYjE9/vjjevDBBzV58mSVl5dr1apVevXVV7V58+a0NQ0AQK8CrKqqSldddZUqKyu7vd7Q0KBjx451e33UqFEqKytTfX39SY/V3t6ueDzebQMAwE/S/zBSU1Oj7du3a+vWrR+pRaNR5efnq7i4uNvrkUhE0Wj0pMerrq7W3XffnWwbAIB+LqkrsKamJs2dO1dPPPGEQqH0/HHYhQsXKhaLdW1NTU1pOS4A4PSWVIA1NDTo4MGDGjdunAKBgAKBgOrq6rRs2TIFAgFFIhEdPXpULS0t3cY1NzertLT0pMcMBoMqKirqtgEA4CepXyFOmTJFu3bt6vba9ddfr1GjRun222/XsGHDlJeXp9raWs2cOVOStGfPHu3bt08VFfZHVwAAkIykAqywsFAXXHBBt9cGDhyos846q+v1G2+8UQsWLFBJSYmKiop06623qqKiQhMnTkxf1xYHfNaS+AmFvJ+rFQh5rwtKh3ct66lCA+y/si0osK87CgUy9zww23IS2/PVJP/nmGXykXW2r3Wq/NbYZFLHMfu5Wyxrpv7UEkt3O12i73qv45L8vx6fuch7TVRF6ELr2Mf/zVr2NfsG7/VUvisZfdaeHvH5HkmF388Nm8QR+0KvREbXaPZM2mduyZIlys3N1cyZM7stZAYAIJ1SDrCXX36528ehUEjLly/X8uXLUz00AACe+FuIAAAnEWAAACcRYAAAJxFgAAAn5RhjTLabOFE8Hlc4HM52GwCALIrFYr5/2IIrMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMIMACAkwgwAICTCDAAgJMC2W4g3T45/DprvaBgoLVePLjYuzYoaB377M/vsdb9zLrhfs/agJD93IMHFdvrIe/Pe96dX7GO9fPYkg29HtvR0WGtBwL2+v+YP73X5/7pSnvftvdKIGD/1vH7vKZfd6m1bvPMT1/p9VhJam1t86wljiSsYzM53yGf93hBQYFnLS9whnXslOnjrHU/62vqez3W/k6QOizfm1+ZPqbX55Wk9S+83euxrT7vhQ6fz+y6FOe8J7gCAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOOm0u42+45j91k7f27ZtNZ9bp1MVsNwKHBoQso71u1U3kbDfEpuK1tZWz1ooZO/bTyAvc3Num2/J/l7xm8/Ww963qqfqPxvfsdb93qe2evGgcK966oni4swd+1jH8YwdW/L/uWGT8Bma6Mjce6X1sPf3ZiLRbh/s8z4KFdiXPZwKXIEBAJxEgAEAnESAAQCcRIABAJxEgAEAnESAAQCcRIABAJx02q0D81sv5bcuKTDAe21DpteB2dZl5KV47kQgtfVYNrY1Mn7rZ/zXHfmsVUmB3zqYjmPe63Nsa98+rGdubU9LS8xa91tvNfjsszxrtkeWZFsm1zKmwu89nvBZCNaRwZ8r0ehBz5rfo3MKCu2PngqEvN9HpwpXYAAAJxFgAAAnEWAAACcRYAAAJxFgAAAnEWAAACcRYAAAJ51268CKQ/ZnPIX8PuMj3ut3EhlckyRJiRbLc7V8vlR+q7wChZlbB2ZbH+e3ds5vDY3f891Scej9FmvdtpYrm337rdVK9RlsmeK3jiuVZ24pg+scJcnWecLvveDzM8dvfCpa/tTifV6/54H5CBRkPz64AgMAOIkAAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOCnHGGOy3cSJ4vG4wmG/Z0QBAE5nsVhMRUVF1n24AgMAOIkAAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOIkAAwA4iQADADiJAAMAOKnPBVgf++P4AIAs6EkW9LkAO3z4cLZbAABkWU+yoM89D6yzs1P79+9XYWGhcnJyFI/HNWzYMDU1Nfk+GwYfYs6Sx5wljzlLHnPmzxijw4cPa8iQIcrNtV9jBU5RTz2Wm5uroUOHfuT1oqIivuBJYs6Sx5wljzlLHnNm19OHGve5XyECANATBBgAwEl9PsCCwaAWLVqkYDCY7VacwZwljzlLHnOWPOYsvfrcTRwAAPREn78CAwDgZAgwAICTCDAAgJMIMACAk/p8gC1fvlyf+MQnFAqFNGHCBP3mN7/Jdkt9xqZNm/TFL35RQ4YMUU5Ojp555pludWOM7rrrLn3sYx/TgAEDVFlZqb1792an2T6gurpan/3sZ1VYWKhzzjlH06dP1549e7rtk0gkVFVVpbPOOksFBQWaOXOmmpubs9Rx3/Dwww9rzJgxXYtvKyoq9Itf/KKrzpzZLV68WDk5OZo3b17Xa8xZevTpAHvqqae0YMECLVq0SNu3b9fYsWM1depUHTx4MNut9QltbW0aO3asli9fftL6/fffr2XLlmnlypXasmWLBg4cqKlTpyqRSJziTvuGuro6VVVVafPmzdq4caOOHTumK664Qm1tbV37zJ8/X+vWrdOaNWtUV1en/fv3a8aMGVnsOvuGDh2qxYsXq6GhQdu2bdPkyZM1bdo0vfHGG5KYM5utW7fqkUce0ZgxY7q9zpylienDxo8fb6qqqro+Pn78uBkyZIiprq7OYld9kySzdu3aro87OztNaWmpeeCBB7pea2lpMcFg0PzsZz/LQod9z8GDB40kU1dXZ4z5cH7y8vLMmjVruvbZvXu3kWTq6+uz1WafNGjQIPPYY48xZxaHDx82I0aMMBs3bjSf//znzdy5c40xvM/Sqc9egR09elQNDQ2qrKzsei03N1eVlZWqr6/PYmduaGxsVDQa7TZ/4XBYEyZMYP7+LBaLSZJKSkokSQ0NDTp27Fi3ORs1apTKysqYsz87fvy4ampq1NbWpoqKCubMoqqqSldddVW3uZF4n6VTn/tjvn9x6NAhHT9+XJFIpNvrkUhEb731Vpa6ckc0GpWkk87fX2r9WWdnp+bNm6dJkybpggsukPThnOXn56u4uLjbvsyZtGvXLlVUVCiRSKigoEBr167V6NGjtXPnTubsJGpqarR9+3Zt3br1IzXeZ+nTZwMMyKSqqiq9/vrr+tWvfpXtVpwwcuRI7dy5U7FYTE8//bRmzZqlurq6bLfVJzU1NWnu3LnauHGjQqFQtts5rfXZXyEOHjxYZ5xxxkfuzGlublZpaWmWunLHX+aI+fuoOXPmaP369XrppZe6PbqntLRUR48eVUtLS7f9mTMpPz9f5513nsrLy1VdXa2xY8fqoYceYs5OoqGhQQcPHtS4ceMUCAQUCARUV1enZcuWKRAIKBKJMGdp0mcDLD8/X+Xl5aqtre16rbOzU7W1taqoqMhiZ24YPny4SktLu81fPB7Xli1b+u38GWM0Z84crV27Vi+++KKGDx/erV5eXq68vLxuc7Znzx7t27ev386Zl87OTrW3tzNnJzFlyhTt2rVLO3fu7NouvvhiXXvttV3/zZylSbbvIrGpqakxwWDQrF692rz55pvmpptuMsXFxSYajWa7tT7h8OHDZseOHWbHjh1GknnwwQfNjh07zDvvvGOMMWbx4sWmuLjYPPvss+a1114z06ZNM8OHDzdHjhzJcufZccstt5hwOGxefvllc+DAga7tgw8+6Nrn5ptvNmVlZebFF18027ZtMxUVFaaioiKLXWffHXfcYerq6kxjY6N57bXXzB133GFycnLML3/5S2MMc9YTJ96FaAxzli59OsCMMeaHP/yhKSsrM/n5+Wb8+PFm8+bN2W6pz3jppZeMpI9ss2bNMsZ8eCv9nXfeaSKRiAkGg2bKlClmz5492W06i042V5LMqlWruvY5cuSImT17thk0aJA588wzzZe//GVz4MCB7DXdB9xwww3m3HPPNfn5+ebss882U6ZM6QovY5iznvjrAGPO0oPHqQAAnNRn/w0MAAAbAgwA4CQCDADgJAIMAOAkAgwA4CQCDADgJAIMAOAkAgwA4CQCDADgJAIMAOAkAgwA4CQCDADgpP8PzV1bPFKedqEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def image_batch_to_patches(image_batch, patch_size):\n",
    "    batch_size, channels, height, width = image_batch.shape\n",
    "    num_patches_height = height // patch_size\n",
    "    num_patches_width = width // patch_size\n",
    "    patches = torch.zeros((batch_size, num_patches_height * num_patches_width,\n",
    "                          channels, patch_size, patch_size), dtype=image_batch.dtype)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        img = image_batch[i]\n",
    "        for h in range(num_patches_height):\n",
    "            for w in range(num_patches_width):\n",
    "                patch = img[:, h * patch_size:(h + 1) * patch_size,\n",
    "                            w * patch_size:(w + 1) * patch_size]\n",
    "                patches[i, h * num_patches_width + w] = patch\n",
    "\n",
    "    return patches\n",
    "\n",
    "def imshow(img):\n",
    "    npimg = img.squeeze().detach().numpy()\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "after_patching = image_batch_to_patches(images, 4)\n",
    "print(after_patching.shape)\n",
    "imshow(torchvision.utils.make_grid(after_patching[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.layerNorm1 = nn.LayerNorm(256)\n",
    "        self.mla = nn.MultiheadAttention(256, 8, 0.2)\n",
    "        self.layerNorm2 = nn.LayerNorm(256)\n",
    "        self.linear1 = nn.Linear(256, 512)\n",
    "        self.gelu = nn.GELU()\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def first_block(self, x):\n",
    "        x = self.layerNorm1(x)\n",
    "        x, _ = self.mla(x, x, x)\n",
    "        return x\n",
    "    \n",
    "    def second_block(self, x):\n",
    "        x = self.layerNorm2(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.first_block(x)\n",
    "        x = x + self.second_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float, dev).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualTransformer(nn.Module):\n",
    "    def __init__(self, num_patches, embedding_dim, num_transformer_blocks):\n",
    "        super(VisualTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(48, embedding_dim)\n",
    "        self.class_token = nn.Parameter(torch.zeros(1, 1, embedding_dim))\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dim, num_patches + 1)\n",
    "        self.transformer_blocks = nn.ModuleList([Transformer() for _ in range(num_transformer_blocks)])\n",
    "        self.layerNorm = nn.LayerNorm(embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = image_batch_to_patches(x, 4)\n",
    "        x = x.view(x.size(0), x.size(1), -1)\n",
    "        x = self.embedding(x)\n",
    "        x = torch.cat((self.class_token.repeat(16, 1, 1), x), dim=1)\n",
    "        x = self.positional_encoding(x)\n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        x = self.layerNorm(x)\n",
    "        x = x[:, 0]\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/michal/MRO/lab6.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m outputs \u001b[39m=\u001b[39m VisualTransformer(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/michal/MRO/lab6.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_encoding(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mfor\u001b[39;00m transformer_block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformer_blocks:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m transformer_block(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayerNorm(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m x \u001b[39m=\u001b[39m x[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/michal/MRO/lab6.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfirst_block(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msecond_block(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;32m/home/michal/MRO/lab6.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfirst_block\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayerNorm1(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmla(x, x, x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/michal/MRO/lab6.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/modules/activation.py:1241\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1228\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1229\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1239\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1240\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1241\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1242\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1243\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1244\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1245\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1246\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1247\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1248\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1249\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1250\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1251\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/MRO/mrenv/lib/python3.10/site-packages/torch/nn/functional.py:5412\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5408\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m dropout(attn_output_weights, p\u001b[39m=\u001b[39mdropout_p)\n\u001b[1;32m   5410\u001b[0m attn_output \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbmm(attn_output_weights, v)\n\u001b[0;32m-> 5412\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39;49mtranspose(\u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39mview(tgt_len \u001b[39m*\u001b[39m bsz, embed_dim)\n\u001b[1;32m   5413\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n\u001b[1;32m   5414\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mview(tgt_len, bsz, attn_output\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VisualTransformer = VisualTransformer(64, 256, 6)\n",
    "epochs = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(VisualTransformer.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = VisualTransformer(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / 2000))\n",
    "    running_loss = 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
